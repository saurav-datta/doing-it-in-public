---
title: gemini diffusion
draft: false
tags:
  - google-gemini
  - diffusion
  - llm
---

“*Traditional autoregressive language models generate text one word – or token – at a time. This sequential process can be slow, and limit the quality and coherence of the output.*

*Diffusion models work differently. Instead of predicting text directly, they learn to generate outputs by refining noise, step-by-step. This means they can iterate on a solution very quickly and error correct during the generation process. This helps them excel at tasks like editing, including in the context of math and code*.”



**Reference**
 - https://deepmind.google/models/gemini-diffusion/
 - https://venturebeat.com/ai/beyond-gpt-architecture-why-googles-diffusion-approach-could-reshape-llm-deployment/
